{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "# !pip install tqdm\n",
    "# !pip install transformers\n",
    "# !pip install scikit-learn\n",
    "# !pip install pandas\n",
    "# !pip install wandb\n",
    "# !pip install evaluate\n",
    "# !pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/leesk/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, AutoConfig, EarlyStoppingCallback\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from customModel import customBertForSequenceClassification, customRobertaForSequenceClassification,customGPT2ForSequenceClassification, customElectraForSequenceClassification\n",
    "from CustomTraniner import CustomTrainer\n",
    "from transformers.configuration_utils import PretrainedConfig\n",
    "import wandb\n",
    "import random\n",
    "from transformers.models.auto.modeling_auto import MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING\n",
    "from frontModelCustom import frontModelDataset, data_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed:int = 42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>tempo(category)</th>\n",
       "      <th>genre</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The melody is mellow and soothing, with a gent...</td>\n",
       "      <td>Allegro</td>\n",
       "      <td>Rock</td>\n",
       "      <td>nostalgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elegant and sweeping orchestral melody with a ...</td>\n",
       "      <td>Moderato</td>\n",
       "      <td>Pop</td>\n",
       "      <td>nostalgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A catchy and memorable tune with a simple yet ...</td>\n",
       "      <td>Andante</td>\n",
       "      <td>Rock</td>\n",
       "      <td>nostalgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The melody is catchy and memorable, with a ble...</td>\n",
       "      <td>Moderato</td>\n",
       "      <td>Rock</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Upbeat and catchy with a memorable melody that...</td>\n",
       "      <td>Allegro</td>\n",
       "      <td>Pop</td>\n",
       "      <td>excitement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             caption tempo(category) genre  \\\n",
       "0  The melody is mellow and soothing, with a gent...         Allegro  Rock   \n",
       "1  Elegant and sweeping orchestral melody with a ...        Moderato   Pop   \n",
       "2  A catchy and memorable tune with a simple yet ...         Andante  Rock   \n",
       "3  The melody is catchy and memorable, with a ble...        Moderato  Rock   \n",
       "4  Upbeat and catchy with a memorable melody that...         Allegro   Pop   \n",
       "\n",
       "      emotion  \n",
       "0   nostalgia  \n",
       "1   nostalgia  \n",
       "2   nostalgia  \n",
       "3        love  \n",
       "4  excitement  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.read_csv('./genre_11_tempo_4.csv')\n",
    "data = pd.read_csv('./data_origin_when_llama2_trot_ballad.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caption</th>\n",
       "      <th>tempo(category)</th>\n",
       "      <th>genre</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the melody is mellow and soothing, with a gent...</td>\n",
       "      <td>Allegro</td>\n",
       "      <td>Rock</td>\n",
       "      <td>nostalgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elegant and sweeping orchestral melody with a ...</td>\n",
       "      <td>Moderato</td>\n",
       "      <td>Pop</td>\n",
       "      <td>nostalgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a catchy and memorable tune with a simple yet ...</td>\n",
       "      <td>Andante</td>\n",
       "      <td>Rock</td>\n",
       "      <td>nostalgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the melody is catchy and memorable, with a ble...</td>\n",
       "      <td>Moderato</td>\n",
       "      <td>Rock</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>upbeat and catchy with a memorable melody that...</td>\n",
       "      <td>Allegro</td>\n",
       "      <td>Pop</td>\n",
       "      <td>excitement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29123</th>\n",
       "      <td>in the darkness, i find solace in the memory o...</td>\n",
       "      <td>Presto</td>\n",
       "      <td>Ballade</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29124</th>\n",
       "      <td>the wind whispers secrets of a love that's yet...</td>\n",
       "      <td>Presto</td>\n",
       "      <td>Ballade</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29125</th>\n",
       "      <td>in the silence of the night, i hear the whispe...</td>\n",
       "      <td>Presto</td>\n",
       "      <td>Ballade</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29126</th>\n",
       "      <td>the shadows on the wall, they whisper secrets ...</td>\n",
       "      <td>Presto</td>\n",
       "      <td>Ballade</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29127</th>\n",
       "      <td>in the darkness, i find solace in the memory o...</td>\n",
       "      <td>Presto</td>\n",
       "      <td>Ballade</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29128 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 caption tempo(category)  \\\n",
       "0      the melody is mellow and soothing, with a gent...         Allegro   \n",
       "1      elegant and sweeping orchestral melody with a ...        Moderato   \n",
       "2      a catchy and memorable tune with a simple yet ...         Andante   \n",
       "3      the melody is catchy and memorable, with a ble...        Moderato   \n",
       "4      upbeat and catchy with a memorable melody that...         Allegro   \n",
       "...                                                  ...             ...   \n",
       "29123  in the darkness, i find solace in the memory o...          Presto   \n",
       "29124  the wind whispers secrets of a love that's yet...          Presto   \n",
       "29125  in the silence of the night, i hear the whispe...          Presto   \n",
       "29126  the shadows on the wall, they whisper secrets ...          Presto   \n",
       "29127  in the darkness, i find solace in the memory o...          Presto   \n",
       "\n",
       "         genre       emotion  \n",
       "0         Rock     nostalgia  \n",
       "1          Pop     nostalgia  \n",
       "2         Rock     nostalgia  \n",
       "3         Rock          love  \n",
       "4          Pop    excitement  \n",
       "...        ...           ...  \n",
       "29123  Ballade  anticipation  \n",
       "29124  Ballade  anticipation  \n",
       "29125  Ballade  anticipation  \n",
       "29126  Ballade  anticipation  \n",
       "29127  Ballade  anticipation  \n",
       "\n",
       "[29128 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.caption = data.caption.apply(lambda x: x.lower())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'emotion_labels' :data.emotion.unique(), 'tempo_labels' : data['tempo(category)'].unique(),\n",
    "              'genre_labels' : data['genre'].unique() }\n",
    "\n",
    "with open('labels.pkl','wb') as f:\n",
    "    pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('labels.pkl','rb') as f:\n",
    "#     pickle.dump(data.emotion.unique(),f)\n",
    "#     pickle.dump(data['tempo(category)'].unique(),f)\n",
    "#     pickle.dump(data['genre'].unique(),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2label_emotion = {k:l for k, l in enumerate(data.emotion.unique())}\n",
    "# label2id_emotion = {l:k for k, l in enumerate(data.emotion.unique())}\n",
    "# id2label_tempo = {k:l for k, l in enumerate(data['tempo(category)'].unique())}\n",
    "# label2id_tempo = {l:k for k, l in enumerate(data['tempo(category)'].unique())}\n",
    "# id2label_genre = {k:l for k, l in enumerate(data['genre'].unique())}\n",
    "# label2id_genre = {l:k for k, l in enumerate(data['genre'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, valid_data = train_test_split(data, stratify=data['emotion'],test_size= 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class frontModelDataset:\n",
    "    def __init__(self, data, tokenizer, label_data_path ='./labels.pkl'):\n",
    "\n",
    "        emotion_labels, tempo_labels, genre_labels= data_labels(label_data_path)\n",
    "        \n",
    "        id2label_emotion = {k:l for k, l in enumerate(emotion_labels)}\n",
    "        label2id_emotion = {l:k for k, l in enumerate(emotion_labels)}\n",
    "        id2label_tempo = {k:l for k, l in enumerate(tempo_labels)}\n",
    "        label2id_tempo = {l:k for k, l in enumerate(tempo_labels)}\n",
    "        id2label_genre = {k:l for k, l in enumerate(genre_labels)}\n",
    "        label2id_genre = {l:k for k, l in enumerate(genre_labels)}\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dataset = []\n",
    "        datas = []\n",
    "        self.labels1 = []\n",
    "        self.labels2 = []\n",
    "        self.labels3 = []\n",
    "        for idx, df in tqdm(data.iterrows()):\n",
    "            label1 = [0. for _ in range(len(id2label_emotion))]\n",
    "            label2 = [0. for _ in range(len(id2label_tempo))]\n",
    "            label3 = [0. for _ in range(len(id2label_genre))]\n",
    "            datas.append(df.caption)\n",
    "            label1[label2id_emotion[df.emotion]] = 1.\n",
    "            label2[label2id_tempo[df['tempo(category)']]] = 1.\n",
    "            label3[label2id_genre[df['genre']]] = 1.\n",
    "            self.labels1.append(label1)\n",
    "            self.labels2.append(label2)\n",
    "            self.labels3.append(label3)\n",
    "        \n",
    "        self.dataset =  tokenizer(datas,padding=True, truncation=True,max_length=512 ,return_tensors=\"pt\").to('cuda')\n",
    "        self.labels1= torch.tensor(self.labels1)\n",
    "        self.labels2= torch.tensor(self.labels2)\n",
    "        self.labels3= torch.tensor(self.labels3)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.dataset.items()}\n",
    "        item['labels1'] = self.labels1[idx].clone().detach()\n",
    "        item['labels2'] = self.labels2[idx].clone().detach()\n",
    "        item['labels3'] = self.labels3[idx].clone().detach()\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion , tempo, genre = data_labels('labels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of customRobertaForSequenceClassification were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized: ['classifier1.bias', 'classifier1.weight', 'classifier2.bias', 'classifier2.weight', 'classifier3.bias', 'classifier3.weight', 'dense1.bias', 'dense1.weight', 'dense2.bias', 'dense2.weight', 'dense3.bias', 'dense3.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "BASE_MODEL = 'SamLowe/roberta-base-go_emotions'\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "config = AutoConfig.from_pretrained(BASE_MODEL)\n",
    "\n",
    "config.num_labels1 = len(labels['emotion_labels'])\n",
    "config.num_labels2 = len(labels['tempo_labels'])\n",
    "config.num_labels3 = len(labels['genre_labels'])\n",
    "# model = customBertForSequenceClassification.from_pretrained(BASE_MODEL, config= config).to(device)\n",
    "model = customRobertaForSequenceClassification.from_pretrained(BASE_MODEL, config= config).to(device)\n",
    "# model = customElectraForSequenceClassification.from_pretrained(BASE_MODEL, config= config).to(device)\n",
    "# model = customGPT2ForSequenceClassification.from_pretrained(BASE_MODEL, config= config).to(device)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.roberta.configuration_roberta.RobertaConfig"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.copy()\n",
    "# emotion_data = data2.groupby('emotion').sample(frac=0.05, random_state=42)\n",
    "# tempo_data = data2.groupby('tempo(category)').sample(frac=0.05, random_state=42)\n",
    "# genre_data = data2.groupby('genre').sample(frac=0.05, random_state=42)\n",
    "# index_total = set(emotion_data.index) | set(tempo_data.index) | set(genre_data.index)\n",
    "# valid_data = data2.iloc[list(index_total)]\n",
    "# train_data = data2.drop(list(index_total)).sample(frac=1, random_state=42)\n",
    "\n",
    "\n",
    "    ## Data split \n",
    "\n",
    "data_valid_index = data.groupby(['emotion','genre','tempo(category)']).sample(frac=0.1, random_state=42).index\n",
    "valid_data = data.iloc[data_valid_index]\n",
    "train_data = data.drop(list(data_valid_index)).sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26207it [00:01, 13581.40it/s]\n",
      "2921it [00:00, 13790.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# dataset_train = frontModelDataset(train_data, tokenizer =tokenizer)\n",
    "# dataset_valid = frontModelDataset(valid_data, tokenizer =tokenizer)\n",
    "\n",
    "dataset_train = frontModelDataset(train_data, tokenizer =tokenizer)\n",
    "dataset_valid = frontModelDataset(valid_data, tokenizer =tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_SCORE_INDICES = range(0,17)\n",
    "CAUSE_INDICES = range(17, 25)\n",
    "def get_preds_from_logits(logits):\n",
    "    ret = np.zeros(logits.shape)\n",
    "    \n",
    "    # The first 5 columns (GLOBAL_SCORE_INDICES) are for global scores. They should be handled with a multiclass approach\n",
    "    # i.e. we fill 1 to the class with highest probability, and 0 into the other columns\n",
    "    best_class = np.argmax(logits, axis=1)\n",
    "    ret[list(range(len(ret))), best_class] = 1\n",
    "    # The other columns are for causes and emotions. They should be handled with multilabel approach.\n",
    "    # i.e. we fill 1 to every class whose score is higher than some threshold\n",
    "    # In this example, we choose that threshold = 0\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "\n",
    "# def sigmoid(x):\n",
    "#    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "\n",
    "#    predictions, labels = eval_pred\n",
    "#    predictions = sigmoid(predictions)\n",
    "#    predictions = (predictions > 0.5).astype(int).reshape(-1)\n",
    "#    return clf_metrics.compute(predictions=predictions, references=labels.astype(int).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    final_metrics = {}\n",
    "    \n",
    "    # Deduce predictions from logits\n",
    "    predictions_emotion = get_preds_from_logits(logits[0])\n",
    "    predictions_tempo = get_preds_from_logits(logits[1])\n",
    "    predictions_genre = get_preds_from_logits(logits[2])\n",
    "    \n",
    "    # Get f1 metrics for global scoring. Notice that f1_micro = accuracy\n",
    "    final_metrics[\"f1_emotion\"] = f1_score(labels[0], predictions_emotion, average=\"micro\")\n",
    "    \n",
    "    # Get f1 metrics for causes\n",
    "    final_metrics[\"f1_tempo\"] = f1_score(labels[1], predictions_tempo, average=\"micro\")\n",
    "    \n",
    "\n",
    "    # The global f1_metrics\n",
    "    final_metrics[\"f1_genre\"] = f1_score(labels[2], predictions_genre, average=\"micro\")\n",
    "\n",
    "    final_metrics['fi_total'] = (final_metrics[\"f1_emotion\"] + final_metrics[\"f1_tempo\"] + final_metrics[\"f1_genre\"])/3\n",
    "    \n",
    "    # Classification report\n",
    "    # print(\"Classification report for global scores: \")\n",
    "    # print(classification_report(labels[:, GLOBAL_SCORE_INDICES], predictions[:, GLOBAL_SCORE_INDICES], zero_division=0))\n",
    "    # print(\"Classification report for causes: \")\n",
    "    # print(classification_report(labels[:, CAUSE_INDICES], predictions[:, CAUSE_INDICES], zero_division=0))\n",
    "    return final_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 4 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mleesk9663\u001b[0m (\u001b[33msanggang\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/leesk/LEVEL3/wandb/run-20240328_230747-8ebn7j9o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sanggang/Final%20project/runs/8ebn7j9o' target=\"_blank\">trot_ballad_SamLowe/roberta-base-go_emotions</a></strong> to <a href='https://wandb.ai/sanggang/Final%20project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sanggang/Final%20project' target=\"_blank\">https://wandb.ai/sanggang/Final%20project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sanggang/Final%20project/runs/8ebn7j9o' target=\"_blank\">https://wandb.ai/sanggang/Final%20project/runs/8ebn7j9o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9828' max='9828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9828/9828 41:33, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Emotion</th>\n",
       "      <th>F1 Tempo</th>\n",
       "      <th>F1 Genre</th>\n",
       "      <th>Fi Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.099800</td>\n",
       "      <td>0.280481</td>\n",
       "      <td>0.344060</td>\n",
       "      <td>0.351592</td>\n",
       "      <td>0.254023</td>\n",
       "      <td>0.316558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.014000</td>\n",
       "      <td>0.249620</td>\n",
       "      <td>0.434440</td>\n",
       "      <td>0.412872</td>\n",
       "      <td>0.306060</td>\n",
       "      <td>0.384457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.974900</td>\n",
       "      <td>0.235189</td>\n",
       "      <td>0.475522</td>\n",
       "      <td>0.397124</td>\n",
       "      <td>0.382746</td>\n",
       "      <td>0.418464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.933900</td>\n",
       "      <td>0.229641</td>\n",
       "      <td>0.505306</td>\n",
       "      <td>0.418692</td>\n",
       "      <td>0.469017</td>\n",
       "      <td>0.464339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.916500</td>\n",
       "      <td>0.219862</td>\n",
       "      <td>0.518658</td>\n",
       "      <td>0.418008</td>\n",
       "      <td>0.476891</td>\n",
       "      <td>0.471186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.214313</td>\n",
       "      <td>0.534748</td>\n",
       "      <td>0.455666</td>\n",
       "      <td>0.497432</td>\n",
       "      <td>0.495949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.864500</td>\n",
       "      <td>0.208162</td>\n",
       "      <td>0.557343</td>\n",
       "      <td>0.469360</td>\n",
       "      <td>0.528586</td>\n",
       "      <td>0.518430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.851600</td>\n",
       "      <td>0.206598</td>\n",
       "      <td>0.547415</td>\n",
       "      <td>0.460801</td>\n",
       "      <td>0.538857</td>\n",
       "      <td>0.515691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.202337</td>\n",
       "      <td>0.568641</td>\n",
       "      <td>0.490243</td>\n",
       "      <td>0.516604</td>\n",
       "      <td>0.525163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.825400</td>\n",
       "      <td>0.197870</td>\n",
       "      <td>0.569668</td>\n",
       "      <td>0.473468</td>\n",
       "      <td>0.547073</td>\n",
       "      <td>0.530070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.823600</td>\n",
       "      <td>0.195001</td>\n",
       "      <td>0.583020</td>\n",
       "      <td>0.488874</td>\n",
       "      <td>0.572064</td>\n",
       "      <td>0.547986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.779900</td>\n",
       "      <td>0.194475</td>\n",
       "      <td>0.583020</td>\n",
       "      <td>0.503252</td>\n",
       "      <td>0.576515</td>\n",
       "      <td>0.554262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.762100</td>\n",
       "      <td>0.191516</td>\n",
       "      <td>0.587812</td>\n",
       "      <td>0.499486</td>\n",
       "      <td>0.572749</td>\n",
       "      <td>0.553349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.763600</td>\n",
       "      <td>0.188646</td>\n",
       "      <td>0.594659</td>\n",
       "      <td>0.523109</td>\n",
       "      <td>0.590209</td>\n",
       "      <td>0.569326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.754200</td>\n",
       "      <td>0.185334</td>\n",
       "      <td>0.603218</td>\n",
       "      <td>0.519343</td>\n",
       "      <td>0.593290</td>\n",
       "      <td>0.571950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.770600</td>\n",
       "      <td>0.182473</td>\n",
       "      <td>0.608011</td>\n",
       "      <td>0.519343</td>\n",
       "      <td>0.592263</td>\n",
       "      <td>0.573206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.702600</td>\n",
       "      <td>0.181756</td>\n",
       "      <td>0.613489</td>\n",
       "      <td>0.536118</td>\n",
       "      <td>0.588155</td>\n",
       "      <td>0.579254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.698300</td>\n",
       "      <td>0.180831</td>\n",
       "      <td>0.620336</td>\n",
       "      <td>0.532352</td>\n",
       "      <td>0.601506</td>\n",
       "      <td>0.584731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.679200</td>\n",
       "      <td>0.181142</td>\n",
       "      <td>0.617939</td>\n",
       "      <td>0.528244</td>\n",
       "      <td>0.593632</td>\n",
       "      <td>0.579938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.177987</td>\n",
       "      <td>0.621363</td>\n",
       "      <td>0.555974</td>\n",
       "      <td>0.606984</td>\n",
       "      <td>0.594773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.671800</td>\n",
       "      <td>0.175316</td>\n",
       "      <td>0.626155</td>\n",
       "      <td>0.551866</td>\n",
       "      <td>0.606299</td>\n",
       "      <td>0.594773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.657100</td>\n",
       "      <td>0.174012</td>\n",
       "      <td>0.627182</td>\n",
       "      <td>0.550839</td>\n",
       "      <td>0.615200</td>\n",
       "      <td>0.597740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>0.174454</td>\n",
       "      <td>0.623074</td>\n",
       "      <td>0.561109</td>\n",
       "      <td>0.616912</td>\n",
       "      <td>0.600365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>0.173748</td>\n",
       "      <td>0.636768</td>\n",
       "      <td>0.561452</td>\n",
       "      <td>0.617597</td>\n",
       "      <td>0.605272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.630948</td>\n",
       "      <td>0.555974</td>\n",
       "      <td>0.628552</td>\n",
       "      <td>0.605158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.623400</td>\n",
       "      <td>0.172578</td>\n",
       "      <td>0.638822</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.622732</td>\n",
       "      <td>0.608924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.606500</td>\n",
       "      <td>0.172875</td>\n",
       "      <td>0.643615</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.619651</td>\n",
       "      <td>0.609494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.560100</td>\n",
       "      <td>0.171945</td>\n",
       "      <td>0.648066</td>\n",
       "      <td>0.562821</td>\n",
       "      <td>0.626498</td>\n",
       "      <td>0.612461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.572600</td>\n",
       "      <td>0.171671</td>\n",
       "      <td>0.642246</td>\n",
       "      <td>0.562479</td>\n",
       "      <td>0.628894</td>\n",
       "      <td>0.611206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>0.169911</td>\n",
       "      <td>0.644300</td>\n",
       "      <td>0.570695</td>\n",
       "      <td>0.625128</td>\n",
       "      <td>0.613374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.563000</td>\n",
       "      <td>0.170693</td>\n",
       "      <td>0.651489</td>\n",
       "      <td>0.570010</td>\n",
       "      <td>0.626155</td>\n",
       "      <td>0.615885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.563800</td>\n",
       "      <td>0.170236</td>\n",
       "      <td>0.644985</td>\n",
       "      <td>0.564533</td>\n",
       "      <td>0.630948</td>\n",
       "      <td>0.613489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory my_awesome_model/checkpoint-6000 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9828, training_loss=0.7521022779940588, metrics={'train_runtime': 2494.8792, 'train_samples_per_second': 63.026, 'train_steps_per_second': 3.939, 'total_flos': 6882682993371360.0, 'train_loss': 0.7521022779940588, 'epoch': 6.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(config.num_labels1, config.num_labels2, config.num_labels3)\n",
    "\n",
    "wandb.init(project=\"Final project\", entity=\"sanggang\",name = \"trot_ballad_\"+BASE_MODEL)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\n",
    "   output_dir=\"my_awesome_model\",\n",
    "   save_steps=300,\n",
    "   eval_steps = 300, \n",
    "   warmup_steps=500,\n",
    "   logging_steps=100,\n",
    "   learning_rate=5e-5,\n",
    "   per_device_train_batch_size=16,\n",
    "   per_device_eval_batch_size=16,\n",
    "   num_train_epochs=6,\n",
    "   weight_decay=0.01,\n",
    "   evaluation_strategy='steps',\n",
    "   load_best_model_at_end = True,\n",
    "   save_total_limit = 2,\n",
    "   report_to=\"wandb\",\n",
    "   metric_for_best_model='fi_total',\n",
    "   # run_name=BASE_MODEL, \n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "\n",
    "   model=model,\n",
    "   args=training_args,\n",
    "   train_dataset=dataset_train,\n",
    "   eval_dataset=dataset_valid,\n",
    "   tokenizer=tokenizer,\n",
    "   data_collator=data_collator,\n",
    "   compute_metrics=compute_metrics,\n",
    "   callbacks = [EarlyStoppingCallback(early_stopping_patience=5)],\n",
    ")\n",
    "\n",
    "\n",
    "# trainer = Trainer(\n",
    "\n",
    "#    model=model,\n",
    "#    args=training_args,\n",
    "#    train_dataset=dataset_train,\n",
    "#    eval_dataset=dataset_valid,\n",
    "#    tokenizer=tokenizer,\n",
    "#    data_collator=data_collator,\n",
    "#    compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
